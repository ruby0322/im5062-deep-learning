{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fe4fc70b",
      "metadata": {
        "id": "fe4fc70b"
      },
      "source": [
        "# Assignment 1 -- MLP\n",
        "\n",
        "## Goal\n",
        "\n",
        "1. Learn to design a MLP architecture.\n",
        "\n",
        "2. Learn to implement activation functions.\n",
        "\n",
        "3. Learn to implement a loss function.\n",
        "\n",
        "4. Learn to implement optimizers and adjust hyper-parameters.\n",
        "\n",
        "\n",
        "## Score\n",
        "\n",
        "1. MLP 15%\n",
        "\n",
        "2. Activation function 15%\n",
        "\n",
        "3. Loss function 15%\n",
        "\n",
        "4. Optimizer 15%\n",
        "\n",
        "6. Model size 15%:\n",
        "\n",
        "* 10%: If your model (the number of parameters) is smaller than 2MB, you will get 10%. Otherwise, no points will be awarded.\n",
        "* 5%:  The remaining 5% will depend on your ranking within the class.\n",
        "\n",
        "7. Model accuracy 15%:\n",
        "\n",
        "* 10%: If your accuracy is higher than 85%, you will get 10%. Otherwise, no points will be awarded.\n",
        "* 5%:  The remaining 5% will depend on your ranking within the class.\n",
        "\n",
        "8. Model accuracy on another dataset 10%: it will depand on your ranking within the class.\n",
        "\n",
        "## Task\n",
        "\n",
        "Please use Google Colab for implementation.\n",
        "\n",
        "In the following instuction, please design a MLP to label images from Fashion-MNIST. Fashion-MNIST is a dataset of Zalando's article imagesâ€”consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes.\n",
        "\n",
        "#### Labels\n",
        "\n",
        "Each training and test example is assigned to one of the following labels:\n",
        "\n",
        "* 0 T-shirt/top\n",
        "* 1 Trouser\n",
        "* 2 Pullover\n",
        "* 3 Dress\n",
        "* 4 Coat\n",
        "* 5 Sandal\n",
        "* 6 Shirt\n",
        "* 7 Sneaker\n",
        "* 8 Bag\n",
        "* 9 Ankle boot\n",
        "\n",
        "You can find more information on https://www.tensorflow.org/datasets/catalog/fashion_mnist.\n",
        "\n",
        "## Rule\n",
        "\n",
        "1. Please do NOT call any existing library for your implementations.\n",
        "2. Please do NOT attempt to modify the sections `DO NOT MODIFY`.\n",
        "\n",
        "## Submission\n",
        "\n",
        "Upload your files to NTU Cool.\n",
        "* This .ipynb file: Please rename this file with the format (DL_HW1_StudentID.ipynb)\n",
        "* Model : .pt file\n",
        "* Output: .csv file\n",
        "\n",
        "Deadline: 3/25 midnight (23:59)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2bc9bec",
      "metadata": {
        "id": "d2bc9bec"
      },
      "source": [
        "Please fill your student ID number below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "674ab9bb",
      "metadata": {
        "id": "674ab9bb"
      },
      "outputs": [],
      "source": [
        "# Please fill your student ID number\n",
        "student_id = 'xxxxx'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abc0d47f",
      "metadata": {
        "id": "abc0d47f"
      },
      "source": [
        "## Part 1\n",
        "\n",
        "`DO NOT MODIFY`\n",
        "\n",
        "Import the necessary libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67e5db5d",
      "metadata": {
        "id": "67e5db5d"
      },
      "outputs": [],
      "source": [
        "# Model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Dataset\n",
        "from torchvision import datasets\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from scipy.io import loadmat\n",
        "\n",
        "# Optimizer\n",
        "from torch.optim.optimizer import Optimizer\n",
        "\n",
        "# Pre-processing\n",
        "import torchvision.transforms as trns\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c316e796",
      "metadata": {
        "id": "c316e796"
      },
      "source": [
        "## Part 2\n",
        "\n",
        "`DO NOT MODIFY`\n",
        "\n",
        "Global variables.\n",
        "\n",
        "Please keep these hyper-parameters unchange."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e882625f",
      "metadata": {
        "id": "e882625f"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "num_classes = 10\n",
        "input_dim = (28 * 28)\n",
        "num_epoch = 10\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "293110f1",
      "metadata": {
        "id": "293110f1"
      },
      "source": [
        "## Part 3\n",
        "\n",
        "`DO NOT MODIFY`\n",
        "\n",
        "Create dataloader with pre-processing of dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f008c646",
      "metadata": {
        "id": "f008c646"
      },
      "outputs": [],
      "source": [
        "# Create train/test transforms\n",
        "train_transform = trns.Compose([\n",
        "    trns.ToTensor(),\n",
        "    trns.Lambda(lambda x: torch.flatten(x)),\n",
        "])\n",
        "\n",
        "test_transform = trns.Compose([\n",
        "    trns.ToTensor(),\n",
        "    trns.Lambda(lambda x: torch.flatten(x)),\n",
        "])\n",
        "\n",
        "# Create train/test datasets with pre-processing\n",
        "# The dataset will automatic download if does not exist\n",
        "data_train = datasets.FashionMNIST(root='./dataset/', train=True, transform=train_transform, download=True)\n",
        "data_test = datasets.FashionMNIST(root='./dataset/', train=False, transform=test_transform, download=True)\n",
        "\n",
        "# Create train/test dataloader for datasets with  pre-processing\n",
        "train_loader = DataLoader(data_train, batch_size=batch_size, shuffle=True)\n",
        "test_loader  = DataLoader(data_test,  batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8b4d224",
      "metadata": {
        "id": "e8b4d224"
      },
      "source": [
        "## Part 4\n",
        "\n",
        "Please implement at least one of following activation functions (15%), and use it to build your MLP.\n",
        "\n",
        "![picture](https://drive.google.com/uc?id=1IemALenuP0kuxEyAgfPTT0JqtVaIUbra)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4ca533e",
      "metadata": {
        "id": "e4ca533e"
      },
      "outputs": [],
      "source": [
        "class myActivation(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # example: identity\n",
        "        out = x\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6eb4e941",
      "metadata": {
        "id": "6eb4e941"
      },
      "source": [
        "Please design you MLP architecture (15%).\n",
        "\n",
        "You can decide the number of layers, the number of hidden neurons of each layer, and the activation function of each layer.\n",
        "Please notice that your score also depands on both the size of your model (the number of parameters) and the accuracy of your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7045cab9",
      "metadata": {
        "id": "7045cab9"
      },
      "outputs": [],
      "source": [
        "class myMLP(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, num_classes):\n",
        "\n",
        "        super(myMLP, self).__init__()\n",
        "\n",
        "        # example: 2 hidden layers, 1 output layer MLP\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(input_dim, 512),\n",
        "            myActivation(),\n",
        "            nn.Linear(512, 512),\n",
        "            myActivation(),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        out = self.mlp(x)\n",
        "\n",
        "        return out\n",
        "\n",
        "model = myMLP(input_dim, num_classes).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41a7d1da",
      "metadata": {
        "id": "41a7d1da"
      },
      "source": [
        "## Part 5\n",
        "\n",
        "Please implement the multiclass cross-entropy loss (15%).\n",
        "\n",
        "![picture](https://drive.google.com/uc?id=1MBwkcvt5thDpc7L8J6htoGEdy0yc2_PN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e16dbca",
      "metadata": {
        "id": "2e16dbca"
      },
      "outputs": [],
      "source": [
        "class myLoss(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        super(myLoss, self).__init__()\n",
        "\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, outputs, targets):\n",
        "\n",
        "        # Transform targets to one-hot vector\n",
        "        # ex.\n",
        "        # 0 => [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "        # 3 => [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
        "        targets_onehot = torch.zeros_like(outputs)\n",
        "        targets_onehot.zero_()\n",
        "        targets_onehot.scatter_(1, targets.unsqueeze(-1), 1)\n",
        "\n",
        "        # example: mean square error loss\n",
        "        loss = (targets_onehot.float() - outputs) ** 2\n",
        "\n",
        "        return torch.mean(loss)\n",
        "\n",
        "criterion = myLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1522cb8a",
      "metadata": {
        "id": "1522cb8a"
      },
      "source": [
        "## Part 6\n",
        "\n",
        "Please implement mini-batch SGD with momentum and weight decay (15%).\n",
        "\n",
        "![picture](https://drive.google.com/uc?id=1TsnWXvJjjsLZX4apuCVKHewzBA35UP_-)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c5df22d",
      "metadata": {
        "id": "3c5df22d"
      },
      "outputs": [],
      "source": [
        "class myOptimizer(Optimizer):\n",
        "\n",
        "    def __init__(self, params, lr=0.01, momentum=0.0, weight_decay=0.0):\n",
        "\n",
        "        defaults = dict(lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
        "        super(myOptimizer, self).__init__(params, defaults)\n",
        "\n",
        "    def step(self, closure=None):\n",
        "\n",
        "        loss = None\n",
        "\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "\n",
        "            for p in group['params']:\n",
        "\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "\n",
        "                # p.data: weight\n",
        "                # p.grad.data: gradient\n",
        "\n",
        "                # example: mini-batch SGD\n",
        "                # new_weight = old_weight + ( -lr * gradient)\n",
        "                p.data.add_(p.grad.data, alpha=-group['lr'])\n",
        "\n",
        "                # hint: momentum need to store additional state, for example 'm_state'.\n",
        "                # following code show how to add new state into the optimizer and how to get stored state\n",
        "\n",
        "                # # add new state\n",
        "                # param_state = self.state[p]\n",
        "                # if 'm_state' not in param_state:\n",
        "                #        param_state['m_state'] = xxx\n",
        "\n",
        "                # # get stored state\n",
        "                # xxx = param_state['m_state']\n",
        "\n",
        "        return loss\n",
        "\n",
        "optimizer = myOptimizer(model.parameters(), 0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d20afbce",
      "metadata": {
        "id": "d20afbce"
      },
      "source": [
        "## Part 7\n",
        "\n",
        "`DO NOT MODIFY`\n",
        "\n",
        "Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "008bdc73",
      "metadata": {
        "id": "008bdc73"
      },
      "outputs": [],
      "source": [
        "model.train()\n",
        "\n",
        "for epoch in range(num_epoch):\n",
        "\n",
        "    losses = []\n",
        "\n",
        "    for batch_num, input_data in enumerate(train_loader):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        x, y = input_data\n",
        "        x = x.to(device).float()\n",
        "        y = y.to(device)\n",
        "\n",
        "        output = model(x)\n",
        "        loss = criterion(output, y)\n",
        "        loss.backward()\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_num % 500 == 0:\n",
        "            print('\\tEpoch %d | Batch %d | Loss %6.4f' % (epoch, batch_num, loss.item()))\n",
        "\n",
        "    print('Epoch %d | Loss %6.4f' % (epoch, sum(losses)/len(losses)))\n",
        "\n",
        "torch.save(model, student_id + '_submission.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed922190",
      "metadata": {
        "id": "ed922190"
      },
      "source": [
        "## Part 8\n",
        "\n",
        "`DO NOT MODIFY`\n",
        "\n",
        "Model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc906220",
      "metadata": {
        "id": "fc906220"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "model.eval()\n",
        "\n",
        "with open(student_id + '_submission.csv', 'w') as f:\n",
        "\n",
        "    fieldnames = ['ImageId', 'Prediction', 'Label']\n",
        "\n",
        "    writer = csv.DictWriter(f, fieldnames=fieldnames, lineterminator = '\\n')\n",
        "    writer.writeheader()\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for x, t in test_loader:\n",
        "\n",
        "            x = x.to(device).float()\n",
        "            output = model(x).argmax(dim=1)\n",
        "\n",
        "            for y,l in zip(output, t):\n",
        "\n",
        "                writer.writerow({fieldnames[0]: (total+1),\n",
        "                                 fieldnames[1]: y.item(),\n",
        "                                 fieldnames[2]: l.item()})\n",
        "\n",
        "                total += 1\n",
        "                if y.item() == l.item():\n",
        "                    correct += 1\n",
        "\n",
        "    print('Accuracy: %6.4f' % (correct / total))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc305626",
      "metadata": {
        "id": "cc305626"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
